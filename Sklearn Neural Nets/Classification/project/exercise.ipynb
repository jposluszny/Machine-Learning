{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn Neural Nets Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in transfusion.data\n",
    "# Predict if someone donated blood in March 2007\n",
    "# (1 stand for donating blood; 0 stands for not donating blood)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training set and a test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the standard scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the training set and test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the MLP Classsifier \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classifier with three layers and 5 nodes each\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.56262128\n",
      "Iteration 2, loss = 0.56127842\n",
      "Iteration 3, loss = 0.55980917\n",
      "Iteration 4, loss = 0.55833702\n",
      "Iteration 5, loss = 0.55725534\n",
      "Iteration 6, loss = 0.55613040\n",
      "Iteration 7, loss = 0.55518668\n",
      "Iteration 8, loss = 0.55408407\n",
      "Iteration 9, loss = 0.55318357\n",
      "Iteration 10, loss = 0.55237821\n",
      "Iteration 11, loss = 0.55155048\n",
      "Iteration 12, loss = 0.55075907\n",
      "Iteration 13, loss = 0.54990587\n",
      "Iteration 14, loss = 0.54912174\n",
      "Iteration 15, loss = 0.54824807\n",
      "Iteration 16, loss = 0.54744723\n",
      "Iteration 17, loss = 0.54669017\n",
      "Iteration 18, loss = 0.54577702\n",
      "Iteration 19, loss = 0.54501784\n",
      "Iteration 20, loss = 0.54423398\n",
      "Iteration 21, loss = 0.54345829\n",
      "Iteration 22, loss = 0.54256709\n",
      "Iteration 23, loss = 0.54184242\n",
      "Iteration 24, loss = 0.54102000\n",
      "Iteration 25, loss = 0.54036911\n",
      "Iteration 26, loss = 0.53951910\n",
      "Iteration 27, loss = 0.53885221\n",
      "Iteration 28, loss = 0.53800317\n",
      "Iteration 29, loss = 0.53719009\n",
      "Iteration 30, loss = 0.53621572\n",
      "Iteration 31, loss = 0.53503855\n",
      "Iteration 32, loss = 0.53364618\n",
      "Iteration 33, loss = 0.53223976\n",
      "Iteration 34, loss = 0.53059952\n",
      "Iteration 35, loss = 0.52898010\n",
      "Iteration 36, loss = 0.52725552\n",
      "Iteration 37, loss = 0.52578721\n",
      "Iteration 38, loss = 0.52445256\n",
      "Iteration 39, loss = 0.52342365\n",
      "Iteration 40, loss = 0.52238815\n",
      "Iteration 41, loss = 0.52131215\n",
      "Iteration 42, loss = 0.52031484\n",
      "Iteration 43, loss = 0.51935453\n",
      "Iteration 44, loss = 0.51848681\n",
      "Iteration 45, loss = 0.51742003\n",
      "Iteration 46, loss = 0.51654616\n",
      "Iteration 47, loss = 0.51570650\n",
      "Iteration 48, loss = 0.51475508\n",
      "Iteration 49, loss = 0.51408574\n",
      "Iteration 50, loss = 0.51312228\n",
      "Iteration 51, loss = 0.51243046\n",
      "Iteration 52, loss = 0.51158969\n",
      "Iteration 53, loss = 0.51087729\n",
      "Iteration 54, loss = 0.51001875\n",
      "Iteration 55, loss = 0.50912418\n",
      "Iteration 56, loss = 0.50824614\n",
      "Iteration 57, loss = 0.50750540\n",
      "Iteration 58, loss = 0.50682674\n",
      "Iteration 59, loss = 0.50596796\n",
      "Iteration 60, loss = 0.50518023\n",
      "Iteration 61, loss = 0.50438203\n",
      "Iteration 62, loss = 0.50367725\n",
      "Iteration 63, loss = 0.50283228\n",
      "Iteration 64, loss = 0.50220209\n",
      "Iteration 65, loss = 0.50143108\n",
      "Iteration 66, loss = 0.50056268\n",
      "Iteration 67, loss = 0.49994701\n",
      "Iteration 68, loss = 0.49920591\n",
      "Iteration 69, loss = 0.49831685\n",
      "Iteration 70, loss = 0.49766891\n",
      "Iteration 71, loss = 0.49696648\n",
      "Iteration 72, loss = 0.49615973\n",
      "Iteration 73, loss = 0.49544606\n",
      "Iteration 74, loss = 0.49478480\n",
      "Iteration 75, loss = 0.49395815\n",
      "Iteration 76, loss = 0.49328725\n",
      "Iteration 77, loss = 0.49267193\n",
      "Iteration 78, loss = 0.49185913\n",
      "Iteration 79, loss = 0.49145748\n",
      "Iteration 80, loss = 0.49065108\n",
      "Iteration 81, loss = 0.49016534\n",
      "Iteration 82, loss = 0.48955024\n",
      "Iteration 83, loss = 0.48891246\n",
      "Iteration 84, loss = 0.48835028\n",
      "Iteration 85, loss = 0.48782879\n",
      "Iteration 86, loss = 0.48723156\n",
      "Iteration 87, loss = 0.48669408\n",
      "Iteration 88, loss = 0.48617477\n",
      "Iteration 89, loss = 0.48544047\n",
      "Iteration 90, loss = 0.48491517\n",
      "Iteration 91, loss = 0.48431866\n",
      "Iteration 92, loss = 0.48376086\n",
      "Iteration 93, loss = 0.48320035\n",
      "Iteration 94, loss = 0.48266209\n",
      "Iteration 95, loss = 0.48224346\n",
      "Iteration 96, loss = 0.48172412\n",
      "Iteration 97, loss = 0.48133146\n",
      "Iteration 98, loss = 0.48080506\n",
      "Iteration 99, loss = 0.48042624\n",
      "Iteration 100, loss = 0.48002191\n",
      "Iteration 101, loss = 0.47967147\n",
      "Iteration 102, loss = 0.47934584\n",
      "Iteration 103, loss = 0.47903721\n",
      "Iteration 104, loss = 0.47873679\n",
      "Iteration 105, loss = 0.47838155\n",
      "Iteration 106, loss = 0.47824502\n",
      "Iteration 107, loss = 0.47791475\n",
      "Iteration 108, loss = 0.47747964\n",
      "Iteration 109, loss = 0.47729132\n",
      "Iteration 110, loss = 0.47695949\n",
      "Iteration 111, loss = 0.47660583\n",
      "Iteration 112, loss = 0.47636506\n",
      "Iteration 113, loss = 0.47608392\n",
      "Iteration 114, loss = 0.47588516\n",
      "Iteration 115, loss = 0.47552800\n",
      "Iteration 116, loss = 0.47530152\n",
      "Iteration 117, loss = 0.47502778\n",
      "Iteration 118, loss = 0.47471907\n",
      "Iteration 119, loss = 0.47449588\n",
      "Iteration 120, loss = 0.47412373\n",
      "Iteration 121, loss = 0.47395712\n",
      "Iteration 122, loss = 0.47357056\n",
      "Iteration 123, loss = 0.47334671\n",
      "Iteration 124, loss = 0.47314208\n",
      "Iteration 125, loss = 0.47293111\n",
      "Iteration 126, loss = 0.47266432\n",
      "Iteration 127, loss = 0.47246341\n",
      "Iteration 128, loss = 0.47229462\n",
      "Iteration 129, loss = 0.47207047\n",
      "Iteration 130, loss = 0.47197172\n",
      "Iteration 131, loss = 0.47176256\n",
      "Iteration 132, loss = 0.47154942\n",
      "Iteration 133, loss = 0.47145079\n",
      "Iteration 134, loss = 0.47137683\n",
      "Iteration 135, loss = 0.47132882\n",
      "Iteration 136, loss = 0.47136779\n",
      "Iteration 137, loss = 0.47109068\n",
      "Iteration 138, loss = 0.47094975\n",
      "Iteration 139, loss = 0.47084663\n",
      "Iteration 140, loss = 0.47074437\n",
      "Iteration 141, loss = 0.47066596\n",
      "Iteration 142, loss = 0.47064607\n",
      "Iteration 143, loss = 0.47052360\n",
      "Iteration 144, loss = 0.47043706\n",
      "Iteration 145, loss = 0.47030033\n",
      "Iteration 146, loss = 0.47025297\n",
      "Iteration 147, loss = 0.47013826\n",
      "Iteration 148, loss = 0.47009770\n",
      "Iteration 149, loss = 0.47005501\n",
      "Iteration 150, loss = 0.46995861\n",
      "Iteration 151, loss = 0.46985303\n",
      "Iteration 152, loss = 0.46985474\n",
      "Iteration 153, loss = 0.46971951\n",
      "Iteration 154, loss = 0.46966949\n",
      "Iteration 155, loss = 0.46964028\n",
      "Iteration 156, loss = 0.46951242\n",
      "Iteration 157, loss = 0.46945125\n",
      "Iteration 158, loss = 0.46937092\n",
      "Iteration 159, loss = 0.46935417\n",
      "Iteration 160, loss = 0.46926611\n",
      "Iteration 161, loss = 0.46924613\n",
      "Iteration 162, loss = 0.46918804\n",
      "Iteration 163, loss = 0.46908107\n",
      "Iteration 164, loss = 0.46897279\n",
      "Iteration 165, loss = 0.46891245\n",
      "Iteration 166, loss = 0.46885602\n",
      "Iteration 167, loss = 0.46869952\n",
      "Iteration 168, loss = 0.46870073\n",
      "Iteration 169, loss = 0.46873405\n",
      "Iteration 170, loss = 0.46857922\n",
      "Iteration 171, loss = 0.46847142\n",
      "Iteration 172, loss = 0.46857254\n",
      "Iteration 173, loss = 0.46830040\n",
      "Iteration 174, loss = 0.46824623\n",
      "Iteration 175, loss = 0.46818640\n",
      "Iteration 176, loss = 0.46813850\n",
      "Iteration 177, loss = 0.46810877\n",
      "Iteration 178, loss = 0.46806267\n",
      "Iteration 179, loss = 0.46800793\n",
      "Iteration 180, loss = 0.46809526\n",
      "Iteration 181, loss = 0.46792711\n",
      "Iteration 182, loss = 0.46797243\n",
      "Iteration 183, loss = 0.46789319\n",
      "Iteration 184, loss = 0.46786472\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(5, 5, 5), max_iter=1000, random_state=101,\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the classifier to the training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the classification metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8044444444444444"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[168,  33],\n",
       "       [ 11,  13]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.84      0.88       201\n",
      "           1       0.28      0.54      0.37        24\n",
      "\n",
      "    accuracy                           0.80       225\n",
      "   macro avg       0.61      0.69      0.63       225\n",
      "weighted avg       0.87      0.80      0.83       225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the classification report \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Happy Learning!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
